
>>> import numpy
>>> import matplotlib.pyplot as plt
>>> import tensorflow as tf
>>> from tensorflow import keras
>>> fashion_mnist = keras.datasets.fashion_mnist
>>> (train_images, train_labels), (test_images, test_labels) = fashion_mnist.loa
d_data()
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-dataset
s/train-labels-idx1-ubyte.gz
32768/29515 [=================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-dataset
s/train-images-idx3-ubyte.gz
26427392/26421880 [==============================] - 4s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-dataset
s/t10k-labels-idx1-ubyte.gz
8192/5148 [===============================================] - 0s 0us/step
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-dataset
s/t10k-images-idx3-ubyte.gz
4423680/4422102 [==============================] - 2s 0us/step
>>> plt.figure()
<Figure size 640x480 with 0 Axes>
>>> plt.imshow(train_images[0])
<matplotlib.image.AxesImage object at 0x00000266965F1080>
>>> plt.colorbar()
<matplotlib.colorbar.Colorbar object at 0x0000026696CCB2E8>
>>> plt.grid(False)
>>> plt.show()
>>> train_images = train_images / 255.0
>>> test_images = test_images / 255.0
>>> model = keras.Sequential([ keras.layers.Flatten(input_shape=(28,28)), keras.
layers.Dense(128, activation=tf.nn.relu), keras.layers.Dense(10, activation=tf.n
n.softmax)])
WARNING:tensorflow:From C:\Users\Avi\Anaconda3\lib\site-packages\tensorflow\pyth
on\ops\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.pytho
n.ops.init_ops) with dtype is deprecated and will be removed in a future version
.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the c
onstructor
>>> >>> model.compile( optimizer = 'adam', loss = 'sparse_categorical_crossentro
py', metrics = ['accuracy'])
  File "<stdin>", line 1
    >>> model.compile( optimizer = 'adam', loss = 'sparse_categorical_crossentro
py', metrics = ['accuracy'])
     ^
SyntaxError: invalid syntax
>>> model.compile( optimizer = 'adam', loss = 'sparse_categorical_crossentropy',
 metrics = ['accuracy'])
>>> model.fit(train_images, train_labels, epochs=5)
2021-10-21 04:20:48.063418: I tensorflow/core/platform/cpu_feature_guard.cc:142]
 Your CPU supports instructions that this TensorFlow binary was not compiled to
use: AVX2
Epoch 1/5
   32/60000 [..............................] - ETA: 2:29 - loss: 2.5053 - acc: 0
 1920/60000 [..............................] - ETA: 3s - loss: 1.1408 - acc: 0.6
 3872/60000 [>.............................] - ETA: 2s - loss: 0.9128 - acc: 0.6
 5888/60000 [=>............................] - ETA: 2s - loss: 0.8200 - acc: 0.7
 7904/60000 [==>...........................] - ETA: 1s - loss: 0.7516 - acc: 0.7
 9952/60000 [===>..........................] - ETA: 1s - loss: 0.7086 - acc: 0.7
11968/60000 [====>.........................] - ETA: 1s - loss: 0.6826 - acc: 0.7
13952/60000 [=====>........................] - ETA: 1s - loss: 0.6656 - acc: 0.7
15968/60000 [======>.......................] - ETA: 1s - loss: 0.6466 - acc: 0.7
17984/60000 [=======>......................] - ETA: 1s - loss: 0.6341 - acc: 0.7
20032/60000 [=========>....................] - ETA: 1s - loss: 0.6169 - acc: 0.7
22080/60000 [==========>...................] - ETA: 1s - loss: 0.6062 - acc: 0.7
24064/60000 [===========>..................] - ETA: 1s - loss: 0.5958 - acc: 0.7
26112/60000 [============>.................] - ETA: 0s - loss: 0.5876 - acc: 0.7
28128/60000 [=============>................] - ETA: 0s - loss: 0.5811 - acc: 0.7
30208/60000 [==============>...............] - ETA: 0s - loss: 0.5721 - acc: 0.8
32256/60000 [===============>..............] - ETA: 0s - loss: 0.5658 - acc: 0.8
34304/60000 [================>.............] - ETA: 0s - loss: 0.5601 - acc: 0.8
36320/60000 [=================>............] - ETA: 0s - loss: 0.5531 - acc: 0.8
38368/60000 [==================>...........] - ETA: 0s - loss: 0.5483 - acc: 0.8
40448/60000 [===================>..........] - ETA: 0s - loss: 0.5432 - acc: 0.8
42496/60000 [====================>.........] - ETA: 0s - loss: 0.5374 - acc: 0.8
44544/60000 [=====================>........] - ETA: 0s - loss: 0.5310 - acc: 0.8
46592/60000 [======================>.......] - ETA: 0s - loss: 0.5265 - acc: 0.8
48640/60000 [=======================>......] - ETA: 0s - loss: 0.5225 - acc: 0.8
50688/60000 [========================>.....] - ETA: 0s - loss: 0.5181 - acc: 0.8
52768/60000 [=========================>....] - ETA: 0s - loss: 0.5156 - acc: 0.8
54848/60000 [==========================>...] - ETA: 0s - loss: 0.5107 - acc: 0.8
56864/60000 [===========================>..] - ETA: 0s - loss: 0.5067 - acc: 0.8
58944/60000 [============================>.] - ETA: 0s - loss: 0.5046 - acc: 0.8
60000/60000 [==============================] - 2s 26us/sample - loss: 0.5028 - a
cc: 0.8242
Epoch 2/5
   32/60000 [..............................] - ETA: 5s - loss: 0.3928 - acc: 0.9
 2080/60000 [>.............................] - ETA: 1s - loss: 0.4382 - acc: 0.8
 4128/60000 [=>............................] - ETA: 1s - loss: 0.4032 - acc: 0.8
 6208/60000 [==>...........................] - ETA: 1s - loss: 0.4117 - acc: 0.8
 8288/60000 [===>..........................] - ETA: 1s - loss: 0.4036 - acc: 0.8
10368/60000 [====>.........................] - ETA: 1s - loss: 0.4027 - acc: 0.8
12416/60000 [=====>........................] - ETA: 1s - loss: 0.3994 - acc: 0.8
14464/60000 [======>.......................] - ETA: 1s - loss: 0.3931 - acc: 0.8
16544/60000 [=======>......................] - ETA: 1s - loss: 0.3924 - acc: 0.8
18624/60000 [========>.....................] - ETA: 1s - loss: 0.3911 - acc: 0.8
20704/60000 [=========>....................] - ETA: 0s - loss: 0.3891 - acc: 0.8
22784/60000 [==========>...................] - ETA: 0s - loss: 0.3892 - acc: 0.8
24800/60000 [===========>..................] - ETA: 0s - loss: 0.3891 - acc: 0.8
26848/60000 [============>.................] - ETA: 0s - loss: 0.3885 - acc: 0.8
28928/60000 [=============>................] - ETA: 0s - loss: 0.3850 - acc: 0.8
31008/60000 [==============>...............] - ETA: 0s - loss: 0.3859 - acc: 0.8
33120/60000 [===============>..............] - ETA: 0s - loss: 0.3851 - acc: 0.8
35168/60000 [================>.............] - ETA: 0s - loss: 0.3851 - acc: 0.8
37216/60000 [=================>............] - ETA: 0s - loss: 0.3845 - acc: 0.8
39264/60000 [==================>...........] - ETA: 0s - loss: 0.3827 - acc: 0.8
41344/60000 [===================>..........] - ETA: 0s - loss: 0.3828 - acc: 0.8
43424/60000 [====================>.........] - ETA: 0s - loss: 0.3824 - acc: 0.8
45504/60000 [=====================>........] - ETA: 0s - loss: 0.3811 - acc: 0.8
47552/60000 [======================>.......] - ETA: 0s - loss: 0.3815 - acc: 0.8
49600/60000 [=======================>......] - ETA: 0s - loss: 0.3814 - acc: 0.8
51648/60000 [========================>.....] - ETA: 0s - loss: 0.3813 - acc: 0.8
53728/60000 [=========================>....] - ETA: 0s - loss: 0.3809 - acc: 0.8
55808/60000 [==========================>...] - ETA: 0s - loss: 0.3805 - acc: 0.8
57888/60000 [===========================>..] - ETA: 0s - loss: 0.3806 - acc: 0.8
59968/60000 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8
60000/60000 [==============================] - 1s 25us/sample - loss: 0.3790 - a
cc: 0.8636
Epoch 3/5
   32/60000 [..............................] - ETA: 5s - loss: 0.3162 - acc: 0.8
 2080/60000 [>.............................] - ETA: 1s - loss: 0.3469 - acc: 0.8
 4160/60000 [=>............................] - ETA: 1s - loss: 0.3405 - acc: 0.8
 6272/60000 [==>...........................] - ETA: 1s - loss: 0.3284 - acc: 0.8
 8352/60000 [===>..........................] - ETA: 1s - loss: 0.3337 - acc: 0.8
10432/60000 [====>.........................] - ETA: 1s - loss: 0.3283 - acc: 0.8
12544/60000 [=====>........................] - ETA: 1s - loss: 0.3308 - acc: 0.8
14560/60000 [======>.......................] - ETA: 1s - loss: 0.3317 - acc: 0.8
16640/60000 [=======>......................] - ETA: 1s - loss: 0.3304 - acc: 0.8
18720/60000 [========>.....................] - ETA: 1s - loss: 0.3325 - acc: 0.8
20800/60000 [=========>....................] - ETA: 0s - loss: 0.3331 - acc: 0.8
22880/60000 [==========>...................] - ETA: 0s - loss: 0.3327 - acc: 0.8
24928/60000 [===========>..................] - ETA: 0s - loss: 0.3326 - acc: 0.8
26944/60000 [============>.................] - ETA: 0s - loss: 0.3336 - acc: 0.8
29024/60000 [=============>................] - ETA: 0s - loss: 0.3332 - acc: 0.8
31104/60000 [==============>...............] - ETA: 0s - loss: 0.3355 - acc: 0.8
33184/60000 [===============>..............] - ETA: 0s - loss: 0.3353 - acc: 0.8
35264/60000 [================>.............] - ETA: 0s - loss: 0.3378 - acc: 0.8
37312/60000 [=================>............] - ETA: 0s - loss: 0.3392 - acc: 0.8
39360/60000 [==================>...........] - ETA: 0s - loss: 0.3375 - acc: 0.8
41472/60000 [===================>..........] - ETA: 0s - loss: 0.3385 - acc: 0.8
43520/60000 [====================>.........] - ETA: 0s - loss: 0.3393 - acc: 0.8
45600/60000 [=====================>........] - ETA: 0s - loss: 0.3389 - acc: 0.8
47680/60000 [======================>.......] - ETA: 0s - loss: 0.3386 - acc: 0.8
49728/60000 [=======================>......] - ETA: 0s - loss: 0.3391 - acc: 0.8
51808/60000 [========================>.....] - ETA: 0s - loss: 0.3390 - acc: 0.8
53888/60000 [=========================>....] - ETA: 0s - loss: 0.3399 - acc: 0.8
55968/60000 [==========================>...] - ETA: 0s - loss: 0.3395 - acc: 0.8
58048/60000 [============================>.] - ETA: 0s - loss: 0.3399 - acc: 0.8
60000/60000 [==============================] - 1s 25us/sample - loss: 0.3393 - a
cc: 0.8758
Epoch 4/5
   32/60000 [..............................] - ETA: 3s - loss: 0.3020 - acc: 0.9
 2080/60000 [>.............................] - ETA: 1s - loss: 0.3090 - acc: 0.8
 4160/60000 [=>............................] - ETA: 1s - loss: 0.3107 - acc: 0.8
 6208/60000 [==>...........................] - ETA: 1s - loss: 0.3145 - acc: 0.8
 8320/60000 [===>..........................] - ETA: 1s - loss: 0.3202 - acc: 0.8
10368/60000 [====>.........................] - ETA: 1s - loss: 0.3202 - acc: 0.8
12480/60000 [=====>........................] - ETA: 1s - loss: 0.3225 - acc: 0.8
14528/60000 [======>.......................] - ETA: 1s - loss: 0.3223 - acc: 0.8
16576/60000 [=======>......................] - ETA: 1s - loss: 0.3174 - acc: 0.8
18656/60000 [========>.....................] - ETA: 1s - loss: 0.3155 - acc: 0.8
20768/60000 [=========>....................] - ETA: 0s - loss: 0.3166 - acc: 0.8
22816/60000 [==========>...................] - ETA: 0s - loss: 0.3167 - acc: 0.8
24896/60000 [===========>..................] - ETA: 0s - loss: 0.3157 - acc: 0.8
26944/60000 [============>.................] - ETA: 0s - loss: 0.3149 - acc: 0.8
29024/60000 [=============>................] - ETA: 0s - loss: 0.3139 - acc: 0.8
31072/60000 [==============>...............] - ETA: 0s - loss: 0.3127 - acc: 0.8
33152/60000 [===============>..............] - ETA: 0s - loss: 0.3126 - acc: 0.8
35232/60000 [================>.............] - ETA: 0s - loss: 0.3147 - acc: 0.8
37312/60000 [=================>............] - ETA: 0s - loss: 0.3143 - acc: 0.8
39328/60000 [==================>...........] - ETA: 0s - loss: 0.3141 - acc: 0.8
41408/60000 [===================>..........] - ETA: 0s - loss: 0.3136 - acc: 0.8
43488/60000 [====================>.........] - ETA: 0s - loss: 0.3134 - acc: 0.8
45568/60000 [=====================>........] - ETA: 0s - loss: 0.3151 - acc: 0.8
47648/60000 [======================>.......] - ETA: 0s - loss: 0.3142 - acc: 0.8
49696/60000 [=======================>......] - ETA: 0s - loss: 0.3146 - acc: 0.8
51744/60000 [========================>.....] - ETA: 0s - loss: 0.3152 - acc: 0.8
53856/60000 [=========================>....] - ETA: 0s - loss: 0.3149 - acc: 0.8
55904/60000 [==========================>...] - ETA: 0s - loss: 0.3152 - acc: 0.8
57984/60000 [===========================>..] - ETA: 0s - loss: 0.3152 - acc: 0.8
60000/60000 [==============================] - 1s 25us/sample - loss: 0.3158 - a
cc: 0.8839
Epoch 5/5
   32/60000 [..............................] - ETA: 3s - loss: 0.3288 - acc: 0.8
 2112/60000 [>.............................] - ETA: 1s - loss: 0.3079 - acc: 0.8
 4160/60000 [=>............................] - ETA: 1s - loss: 0.2989 - acc: 0.8
 6240/60000 [==>...........................] - ETA: 1s - loss: 0.2900 - acc: 0.8
 8288/60000 [===>..........................] - ETA: 1s - loss: 0.2975 - acc: 0.8
10368/60000 [====>.........................] - ETA: 1s - loss: 0.2952 - acc: 0.8
12448/60000 [=====>........................] - ETA: 1s - loss: 0.2967 - acc: 0.8
14496/60000 [======>.......................] - ETA: 1s - loss: 0.2987 - acc: 0.8
16544/60000 [=======>......................] - ETA: 1s - loss: 0.2978 - acc: 0.8
18624/60000 [========>.....................] - ETA: 1s - loss: 0.2973
- acc: 0.820704/60000 [=========>....................] - ETA: 0s - los
s: 0.2992 - acc: 0.822784/60000 [==========>...................] - ETA
: 0s - loss: 0.2994 - acc: 0.824864/60000 [===========>...............
...] - ETA: 0s - loss: 0.3000 - acc: 0.826912/60000 [============>..............
...] - ETA: 0s - loss: 0.3003 - acc: 0.828960/60000 [=============>.............
...] - ETA: 0s - loss: 0.2985 - acc: 0.831040/60000 [==============>............
...] - ETA: 0s - loss: 0.2989 - acc: 0.833120/60000 [===============>...........
...] - ETA: 0s - loss: 0.3015 - acc: 0.835200/60000 [================>..........
...] - ETA: 0s - loss: 0.3018 - acc: 0.837248/60000 [=================>.........
...] - ETA: 0s - loss: 0.3028 - acc: 0.839296/60000 [==================>........
...] - ETA: 0s - loss: 0.3033 - acc: 0.841376/60000 [===================>.......
...] - ETA: 0s - loss: 0.3040 - acc: 0.843456/60000 [====================>......
...] - ETA: 0s - loss: 0.3026 - acc: 0.845536/60000 [=====================>.....
...] - ETA: 0s - loss: 0.3021 - acc: 0.847584/60000 [======================>....
...] - ETA: 0s - loss: 0.3014 - acc: 0.849664/60000 [=======================>...
...] - ETA: 0s - loss: 0.3012 - acc: 0.851712/60000 [========================>..
...] - ETA: 0s - loss: 0.2998 - acc: 0.853792/60000 [=========================>.
...] - ETA: 0s - loss: 0.2987 - acc: 0.855840/60000 [==========================>
...] - ETA: 0s - loss: 0.2980 - acc: 0.857920/60000 [===========================
>..] - ETA: 0s - loss: 0.2971 - acc: 0.860000/60000 [===========================
===] - 1s 25us/sample - loss: 0.2968 - acc: 0.8898
<tensorflow.python.keras.callbacks.History object at 0x0000026696FFEF60>
>>> test_loss, test_acc = model.evaluate(test_images, test_labels)
   32/10000 [..............................] - ETA: 4s - loss: 0.2849 - acc: 0.8
 3712/10000 [==========>...................] - ETA: 0s - loss: 0.3531 - acc: 0.8
 7488/10000 [=====================>........] - ETA: 0s - loss: 0.3524 - acc: 0.8
10000/10000 [==============================] - 0s 15us/sample - loss: 0.3474 - a
cc: 0.8757
>>> print(test_acc)
0.8757
>>> predictions = model.predict(test_images)
>>> predictions[0]
array([9.8420314e-06, 7.2155451e-09, 9.6925589e-08, 1.4566164e-07,
       1.7584373e-06, 4.4139143e-02, 1.4727021e-05, 6.6156671e-03,
       8.3295279e-05, 9.4913530e-01], dtype=float32)
>>> numpy.argmax(predictions[0])
9
>>> test_labels[0]
9
>>>
